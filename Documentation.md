# Клъстерен анализ и влияние на метриките за разстояние

## Въведение

Това хранилище съдържа имплементация на проект за клъстерен анализ, който изследва как различните метрики за разстояние влияят върху резултатите от клъстеризацията. Проектът е разработен като част от курс по линейна алгебра и приложения в анализа на данни.

## Теоретична основа

### Какво представлява клъстерният анализ?

Клъстерният анализ е техника от несупервизираното машинно обучение, която цели да групира данни в смислени подгрупи (клъстери) без предварително дефинирани етикети. Целта е да се открият естествените структури и групи в данните.

Основният принцип зад клъстеризацията е:
- Точките в един клъстер трябва да са подобни помежду си
- Точките от различни клъстери трябва да са различни

### Метрики за разстояние и тяхното значение

Различните метрики измерват "разстоянието" между точките по различни начини, което може да доведе до значителни разлики в резултатите:

- **Евклидово разстояние**: Директната линия между две точки в пространството. Формално: √Σ(xᵢ - yᵢ)²
- **Манхатън разстояние**: Сума от абсолютните разлики по всички измерения. Формално: Σ|xᵢ - yᵢ|
- **Чебишев разстояние**: Максималната разлика между всички измерения. Формално: max|xᵢ - yᵢ|
- **Косинусово разстояние**: Измерва ъгъла между векторите, игнорирайки техния размер

## Имплементирани алгоритми

### K-means

K-means е популярен алгоритъм за клъстеризация, който разделя данните на K предварително определени групи. Алгоритъмът работи итеративно, като:
1. Инициализира K центрове на клъстери
2. Присвоява всяка точка към най-близкия център
3. Преизчислява центровете като средното на всички точки в клъстера
4. Повтаря стъпки 2-3 до конвергенция

K-means по подразбиране използва евклидово разстояние.

### Йерархична (агломеративна) клъстеризация

Йерархичната клъстеризация създава дървовидна структура от клъстери. Агломеративният подход започва с всяка точка в отделен клъстер и последователно обединява най-близките клъстери. Предимството е, че можем да използваме различни метрики за разстояние.

## Функционалности на проекта

### Генериране на синтетични данни

Проектът включва функционалност за генериране на 4 различни типа синтетични данни:
- Стандартни клъстери (blobs)
- Нелинейни полумесец-образни клъстери (moons)
- Анизотропни клъстери (разтеглени в различни посоки)
- Клъстери с различна плътност

### Визуализация на клъстерите

Имплементирани са функции за визуализация на:
- Оригиналните данни и истинските клъстери
- Клъстерите, получени от различните алгоритми
- Сравнение между различните метрики

### Оценка на качеството на клъстеризация

За измерване на качеството на клъстеризацията използваме силует скор (silhouette score), който оценява колко добре е групирана всяка точка. Стойности близки до:
- 1 означават добра клъстеризация
- 0 показват припокриващи се клъстери
- -1 могат да индикират грешна клъстеризация

## Експериментални резултати

### Влияние на метриките върху различни типове данни

Експериментите показват, че:
- **Евклидово разстояние** работи най-добре за кръгови/сферични клъстери
- **Манхатън разстояние** е подходящо за данни, следващи координатна мрежа
- **Косинусово разстояние** е полезно за високо-размерни данни, където ъгълът между векторите е важен
- **Чебишев разстояние** може да открива клъстери, съдържащи се в "кубове" в пространството

### Влияние на инициализацията при K-means

Анализът на различните стойности на параметъра `n_init` при K-means показва, че:
- По-голям брой инициализации води до по-стабилни резултати
- Има компромис между стабилност и време за изпълнение
- Препоръчва се използването на поне 10 инициализации за повечето приложения

### Приложение върху реални данни

Проектът включва приложение на клъстерния анализ върху набора от данни Olivetti Faces, който съдържа лица на различни хора. Резултатите показват, че:
- Косинусовото разстояние дава по-добри резултати за разпознаване на лица
- K-means се справя по-добре с откриването на основните характеристики на лицата
- Йерархичната клъстеризация може да открие по-фини детайли, но е по-чувствителна към шум

## Заключения

Основните изводи от проекта са:

1. **Изборът на метрика е критичен** за качеството на клъстеризацията и зависи от:
   - Формата и структурата на данните
   - Наличието на шум
   - Специфичните нужди на приложението

2. **Не съществува универсална метрика**, която да работи най-добре за всички типове данни

3. **Предварителната обработка на данните** (нормализация, стандартизация) е също толкова важна, колкото избора на метрика

4. **Визуализацията на резултатите** помага за по-добро разбиране на влиянието на различните метрики

## Бъдещо развитие

Възможни направления за бъдещо развитие на проекта:
- Имплементация на допълнителни метрики (напр. Махаланобис, корелационно разстояние)
- Изследване на техники за автоматично определяне на оптималния брой клъстери
- Прилагане на анализа върху по-разнообразни реални набори от данни
- Разработване на хибридни метрики, които комбинират предимствата на различните подходи

## Използвана литература

- Scikit-learn документация: [Clustering](https://scikit-learn.org/stable/modules/clustering.html)
- Aggarwal, C. C., & Reddy, C. K. (2013). Data clustering: algorithms and applications. CRC press.
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media.
